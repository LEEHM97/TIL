{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"hfkjeyTdIIK2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667801232228,"user_tz":-540,"elapsed":27697,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}},"outputId":"629b6bfc-5961-44c6-fbcb-ac36f59fe338"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# 드라이브 마운트 하기\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["shared_dir = '/content/drive/MyDrive/test1/'"],"metadata":{"id":"OQ6jTMvzeyKY","executionInfo":{"status":"ok","timestamp":1667801292819,"user_tz":-540,"elapsed":609,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5HnfAqgiIJHU"},"source":["# 데이터 준비"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"D_l9VlYWE40v","executionInfo":{"status":"ok","timestamp":1667801294205,"user_tz":-540,"elapsed":2,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"outputs":[],"source":["# 필요한 라이브러리 불러오기\n","\n","import os\n","import pandas as pd\n","import json\n","import numpy as np\n","from sklearn.preprocessing import OneHotEncoder\n","\n","import torch\n","from torch import nn \n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.autograd import Variable\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"9vT8Bfc0Exp2","executionInfo":{"status":"ok","timestamp":1667801295533,"user_tz":-540,"elapsed":928,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"outputs":[],"source":["# \bneo-antigen 데이터 불러오기\n","# antigen: epitope sequence\n","# full_seq: HLA full sequence \n","# label: 정답 값 (epitope와 HLA의 affinity)\n","\n","neo = pd.read_csv(shared_dir + 'NeoAntigen_dataset_for_training.csv')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":468},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1667801297139,"user":{"displayName":"seungho cook","userId":"04623047230260438237"},"user_tz":-540},"id":"0nw4ivFAFOJ6","outputId":"dc072c51-0e01-4779-b446-dab0e4d7ed55"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["         antigen  allele_name  \\\n","0      EVMPVSMAK  HLA-A*11:01   \n","1      ATFSVPMEK  HLA-A*11:01   \n","2      RVFNNYMPY  HLA-A*11:01   \n","3      ATVVIGTSK  HLA-A*11:01   \n","4      SSNVANYQK  HLA-A*11:01   \n","...          ...          ...   \n","62643  SYIDRLAPR  HLA-A*33:03   \n","62644  VVAAVRWRR  HLA-A*33:03   \n","62645  YVFPKPFNR  HLA-A*33:03   \n","62646  YVQRFHYSR  HLA-A*33:03   \n","62647  YYYYHRQYR  HLA-A*33:03   \n","\n","                                                full_seq  \\\n","0      MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFYTSVSRPGRGEPRF...   \n","1      MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFYTSVSRPGRGEPRF...   \n","2      MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFYTSVSRPGRGEPRF...   \n","3      MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFYTSVSRPGRGEPRF...   \n","4      MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFYTSVSRPGRGEPRF...   \n","...                                                  ...   \n","62643  MAVMAPRTLLLLLLGALALTQTWAGSHSMRYFTTSVSRPGRGEPRF...   \n","62644  MAVMAPRTLLLLLLGALALTQTWAGSHSMRYFTTSVSRPGRGEPRF...   \n","62645  MAVMAPRTLLLLLLGALALTQTWAGSHSMRYFTTSVSRPGRGEPRF...   \n","62646  MAVMAPRTLLLLLLGALALTQTWAGSHSMRYFTTSVSRPGRGEPRF...   \n","62647  MAVMAPRTLLLLLLGALALTQTWAGSHSMRYFTTSVSRPGRGEPRF...   \n","\n","                               pseudo_seq  label  \n","0      YYAMYQENVAQTDVDTLYIIYRDYTWAAQAYRWY    1.0  \n","1      YYAMYQENVAQTDVDTLYIIYRDYTWAAQAYRWY    1.0  \n","2      YYAMYQENVAQTDVDTLYIIYRDYTWAAQAYRWY    1.0  \n","3      YYAMYQENVAQTDVDTLYIIYRDYTWAAQAYRWY    1.0  \n","4      YYAMYQENVAQTDVDTLYIIYRDYTWAAQAYRWY    1.0  \n","...                                   ...    ...  \n","62643  YTAMYRNNVAHIDVDTLYIMYQDYTWAVLAYTWY    1.0  \n","62644  YTAMYRNNVAHIDVDTLYIMYQDYTWAVLAYTWY    1.0  \n","62645  YTAMYRNNVAHIDVDTLYIMYQDYTWAVLAYTWY    1.0  \n","62646  YTAMYRNNVAHIDVDTLYIMYQDYTWAVLAYTWY    1.0  \n","62647  YTAMYRNNVAHIDVDTLYIMYQDYTWAVLAYTWY    1.0  \n","\n","[62648 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-6f0a9309-98a7-4685-958c-d503f0ebeba4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>antigen</th>\n","      <th>allele_name</th>\n","      <th>full_seq</th>\n","      <th>pseudo_seq</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>EVMPVSMAK</td>\n","      <td>HLA-A*11:01</td>\n","      <td>MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFYTSVSRPGRGEPRF...</td>\n","      <td>YYAMYQENVAQTDVDTLYIIYRDYTWAAQAYRWY</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ATFSVPMEK</td>\n","      <td>HLA-A*11:01</td>\n","      <td>MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFYTSVSRPGRGEPRF...</td>\n","      <td>YYAMYQENVAQTDVDTLYIIYRDYTWAAQAYRWY</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>RVFNNYMPY</td>\n","      <td>HLA-A*11:01</td>\n","      <td>MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFYTSVSRPGRGEPRF...</td>\n","      <td>YYAMYQENVAQTDVDTLYIIYRDYTWAAQAYRWY</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ATVVIGTSK</td>\n","      <td>HLA-A*11:01</td>\n","      <td>MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFYTSVSRPGRGEPRF...</td>\n","      <td>YYAMYQENVAQTDVDTLYIIYRDYTWAAQAYRWY</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>SSNVANYQK</td>\n","      <td>HLA-A*11:01</td>\n","      <td>MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFYTSVSRPGRGEPRF...</td>\n","      <td>YYAMYQENVAQTDVDTLYIIYRDYTWAAQAYRWY</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>62643</th>\n","      <td>SYIDRLAPR</td>\n","      <td>HLA-A*33:03</td>\n","      <td>MAVMAPRTLLLLLLGALALTQTWAGSHSMRYFTTSVSRPGRGEPRF...</td>\n","      <td>YTAMYRNNVAHIDVDTLYIMYQDYTWAVLAYTWY</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>62644</th>\n","      <td>VVAAVRWRR</td>\n","      <td>HLA-A*33:03</td>\n","      <td>MAVMAPRTLLLLLLGALALTQTWAGSHSMRYFTTSVSRPGRGEPRF...</td>\n","      <td>YTAMYRNNVAHIDVDTLYIMYQDYTWAVLAYTWY</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>62645</th>\n","      <td>YVFPKPFNR</td>\n","      <td>HLA-A*33:03</td>\n","      <td>MAVMAPRTLLLLLLGALALTQTWAGSHSMRYFTTSVSRPGRGEPRF...</td>\n","      <td>YTAMYRNNVAHIDVDTLYIMYQDYTWAVLAYTWY</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>62646</th>\n","      <td>YVQRFHYSR</td>\n","      <td>HLA-A*33:03</td>\n","      <td>MAVMAPRTLLLLLLGALALTQTWAGSHSMRYFTTSVSRPGRGEPRF...</td>\n","      <td>YTAMYRNNVAHIDVDTLYIMYQDYTWAVLAYTWY</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>62647</th>\n","      <td>YYYYHRQYR</td>\n","      <td>HLA-A*33:03</td>\n","      <td>MAVMAPRTLLLLLLGALALTQTWAGSHSMRYFTTSVSRPGRGEPRF...</td>\n","      <td>YTAMYRNNVAHIDVDTLYIMYQDYTWAVLAYTWY</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>62648 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f0a9309-98a7-4685-958c-d503f0ebeba4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6f0a9309-98a7-4685-958c-d503f0ebeba4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6f0a9309-98a7-4685-958c-d503f0ebeba4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}],"source":["neo"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":396,"status":"ok","timestamp":1667801298705,"user":{"displayName":"seungho cook","userId":"04623047230260438237"},"user_tz":-540},"id":"gnUqNy-mF659","outputId":"4ca286b5-3632-4418-ae33-42ae9e60ddd8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# epitops sequence 길이 분포 살펴보기\n","\n","neo['antigen'].apply(lambda x: len(x)).plot.hist()\n","max_seq_epitope = neo['antigen'].apply(lambda x: len(x)).max() # 최대 epitope 길이를 max sequence로 활용하기"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":718,"status":"ok","timestamp":1667801299420,"user":{"displayName":"seungho cook","userId":"04623047230260438237"},"user_tz":-540},"id":"AhSmj3V8M9zJ","outputId":"1c78a9a3-fed0-4c17-db03-8fccc21bdaef"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# HLA sequenc 길이 분포 살펴보기 \n","\n","neo['full_seq'].apply(lambda x: len(x)).plot.hist()\n","max_seq_hla = neo['full_seq'].apply(lambda x: len(x)).max() # 최대 HLA 길이를 max sequence로 활용"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"-u8m-40GalcD","executionInfo":{"status":"ok","timestamp":1667801299421,"user_tz":-540,"elapsed":5,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"7mwCijKsIQiq"},"source":["# 데이터 전처리 (pre-processing)"]},{"cell_type":"code","source":["!pip install subword_nmt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"45VmVd03eKZI","executionInfo":{"status":"ok","timestamp":1667801304565,"user_tz":-540,"elapsed":3361,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}},"outputId":"68a0ccf6-b01b-479b-aa1d-85ad09820a0e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting subword_nmt\n","  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n","Collecting mock\n","  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from subword_nmt) (4.64.1)\n","Installing collected packages: mock, subword-nmt\n","Successfully installed mock-4.0.3 subword-nmt-0.3.8\n"]}]},{"cell_type":"code","source":["# Byte Pair Encoding을 위한 라이브러리 \n","from subword_nmt.apply_bpe import BPE"],"metadata":{"id":"XLU5Br0TeLhr","executionInfo":{"status":"ok","timestamp":1667801304566,"user_tz":-540,"elapsed":8,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["**Epitope processing**\n","---\n","이전 강의와 같은 방식으로 epitope one-hot encoding 수행\n"],"metadata":{"id":"SeejVjopeBRf"}},{"cell_type":"code","source":["amino_char = ['?', 'A', 'C', 'B', 'E', 'D', 'G', 'F', 'I', 'H', 'K', 'M', 'L', 'O',\n","       'N', 'Q', 'P', 'S', 'R', 'U', 'T', 'W', 'V', 'Y', 'X', 'Z']\n","\n","# protein, drug 원핫(one-hot) 인코더\n","enc_protein = OneHotEncoder().fit(np.array(amino_char).reshape(-1, 1))"],"metadata":{"id":"yTCusCJRf4n7","executionInfo":{"status":"ok","timestamp":1667801304566,"user_tz":-540,"elapsed":6,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def trans_protein(x, max_seq_protein):\n","    \"\"\"Protein sequence 데이터 전처리하기\n","\n","    같은 크기(max_seq_protein)의 리스트로 만들기\n","    사전 정의된 character에 해당 되지 않는 값은 ?로 변환\n","\n","    Args:\n","        x, string: 하나의 sequence 데이터 \n","    \n","    Return:\n","        전처리된 SMILES 데이터 리스트\n","    \"\"\"\n","    temp = list(x.upper()) # 대문자로 바꾸기\n","    temp = [i if i in amino_char else '?' for i in temp] # \n","\n","    if len(temp) < max_seq_protein:\n","        # max_seq_protein 보다 작으면 뒷부분을 ?로 채워서 MAX_SEQ_DRUG 길이의 리스트로 만들기\n","        temp = temp + ['?'] * (max_seq_protein - len(temp))\n","    else:\n","        # max_seq_protein 보다 크면 앞에서부터 MAX_SEQ_DRUG 만큼 슬라이싱\n","        temp = temp [:max_seq_protein]\n","\n","    return temp"],"metadata":{"id":"3K2-m8i3gI5j","executionInfo":{"status":"ok","timestamp":1667801306584,"user_tz":-540,"elapsed":3,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Eir3gwKKJ74h","executionInfo":{"status":"ok","timestamp":1667801306892,"user_tz":-540,"elapsed":4,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["**HLA processing**\n","---\n","Byte Pair Encoding을 이용한 HLA encoding"],"metadata":{"id":"KTG4Pqb8frFJ"}},{"cell_type":"code","source":["# protein subword data 불러오기\n","\n","vocab_path = shared_dir + \"protein_codes_uniprot_2000.txt\" \n","bpe_codes_protein = open(vocab_path)\n","pbpe = BPE(bpe_codes_protein, merges=-1, separator='')\n","sub_csv = pd.read_csv(shared_dir + \"subword_units_map_uniprot_2000.csv\") # subword vocab"],"metadata":{"id":"Bg_6tQnYJ72e","executionInfo":{"status":"ok","timestamp":1667801308933,"user_tz":-540,"elapsed":819,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["full_seq = pd.Series(neo[\"full_seq\"])[0]\n","print(full_seq)\n","print(pbpe.process_line(full_seq))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pgV7YIuv1h2F","executionInfo":{"status":"ok","timestamp":1667801308933,"user_tz":-540,"elapsed":3,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}},"outputId":"d0141f90-885c-45b3-a297-0a1f9b1fe4ed"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFYTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDQETRNVKAQSQTDRVDLGTLRGYYNQSEDGSHTIQIMYGCDVGPDGRFLRGYRQDAYDGKDYIALNEDLRSWTAADMAAQITKRKWEAAHAAEQQRAYLEGRCVEWLRRYLENGKETLQRTDPPKTHMTHHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRWELSSQPTIPIVGIIAGLVLLGAVITGAVVAAVMWRRKSSDRKGGSYTQAASSDSAQGSDVSLTACKV\n","MAV MAP RT LL LLL SG ALAL TQ TW AGS HS MRY FY TS VS RPG RG EP RF I AVG Y VDD TQ FVR F DSD AAS QR ME PR AP WIE QEG PE Y WD QE TR NVK AQ SQ TD RV DLG TL RG YY NQ SE DGS HT IQ IM YG CD VG PDG RFL RG YR QD AY DG KD YI ALNE DL RS W TAA DM AAQ IT KR K WE AA H AAE QQ R AYL EG RC VE WL RR YLE NG KETL QR TD PP KT HM TH HP ISD HE ATL RC W ALG FYP AE ITL TW QR DG ED QT QD TEL VE TR PAG DG TF QK WAA VV VP SG EE QR YT CH VQ HE GL PK PLTL RW ELSS QP TIP IVG II AGL VLLG AV ITG AV VAA VM WRR KSS D RK GG SY TQ AASS DS AQG SD VSL TAC K V\n"]}]},{"cell_type":"markdown","source":["[subword-mnt github](https://github.com/rsennrich/subword-nmthttps://)"],"metadata":{"id":"UdBGyUkQ3W6M"}},{"cell_type":"code","source":["idx2word_p = sub_csv['index'].values\n","words2idx_p = dict(zip(idx2word_p, range(0, len(idx2word_p)))) # subword : index"],"metadata":{"id":"L-PkIoE9J70J","executionInfo":{"status":"ok","timestamp":1667801309254,"user_tz":-540,"elapsed":1,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["\n","def hla2emb_encoder(x):\n","    t1 = pbpe.process_line(x).split()  # protein sequence subword로 나누기\n","    try:\n","        i1 = np.asarray([words2idx_p[i] for i in t1])  # 단어 집합에 있는 경우 해당 index 가져오기 \n","    except:\n","        i1 = np.array([0]) # 없는 경우 0으로 채우기\n","\n","    l = len(i1) # 전체 sequence 길이\n","   \n","    if l < max_seq_hla:\n","        # max_seq 보다 작으면 나머지 부분 0으로 채우기\n","        i = np.pad(i1, (0, max_seq_hla - l), 'constant', constant_values = 0) # 0으로 채우기 (zero padding)\n","        input_mask = ([1] * l) + ([0] * (max_seq_hla - l)) # zero padding 한 부분 이 후 transformer에서 masking\n","    else:\n","        # max_seq 보다 크면 max_seq 만큼 앞에서부터 slicing\n","        i = i1[:max_seq_hla]\n","        input_mask = [1] * max_seq_hla \n","        \n","    return i, np.asarray(input_mask)"],"metadata":{"id":"rnUwOmJeJ7x8","executionInfo":{"status":"ok","timestamp":1667801309254,"user_tz":-540,"elapsed":1,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["\n","t1 = pbpe.process_line(full_seq).split()  # protein sequence subword로 나누기\n","\n","try:\n","    i1 = np.asarray([words2idx_p[i] for i in t1])  # 단어 집합에 있는 경우 해당 index 가져오기 \n","except:\n","    i1 = np.array([0]) # 없는 경우 0으로 채우기\n","\n","i1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xiFAA_aP3qU1","executionInfo":{"status":"ok","timestamp":1667801309640,"user_tz":-540,"elapsed":8,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}},"outputId":"dced471b-645e-4008-d6cf-24f5b2ff589c"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 873, 1560,  159,   25,  194,   45, 1701,  172,  347,  482,  158,\n","       2934,  204,   94,   64,  806,   78,  249,  153,   22,  326,   12,\n","        789,  172, 1382,    3,  971,  381,  136,  137,  260,   83, 2360,\n","        730,   65,   12,  331,  104,  135, 1307,   72,  276,  127,  200,\n","        352,   35,   78,  250,  288,   88,  589,  297,  144,  293,  108,\n","        303,   58, 1015,  786,   78,  257,  156,  114,   73,  112,  325,\n","       3850,   36,  107,   23,  443,  360,  975,   79,  110,   15,  302,\n","         26,   24,  332,   98,   18,  425,  146,  370,   54,  145,   61,\n","        800,   81, 3239,  136,  127,  115,  116,  590,  215,  175,  835,\n","        170,  274,  370,   23,  251, 2778,   43,  686,  347,  136,   73,\n","        191,  205,  156,  666,   54,  135,  983,   73,  147,  196, 1940,\n","         42,   90,   45,   34,  136,  272,  496,  120,  170,   29,  280,\n","       3403,  372, 3357,  163, 1254,  558,  122,  218, 2673,   39,  696,\n","         39,  299,  155, 2164,  659,   21,  168,   32,  296,  172, 3275,\n","        106,  479,  165,  397, 2371,   15,    6])"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["**전체 데이터 전처리 & 데이터 나누기**"],"metadata":{"id":"0LC6FjpfgJu_"}},{"cell_type":"code","source":["def create_fold(df, fold_seed, frac):\n","    \"\"\"Train / Val / Test 나누기\n","\n","    Args:\n","        df: 전체 데이터 (Pandas DataFrame)\n","        fold_seed: random_state for random sampling\n","        frac: train - val - test fraction (list or tuple) ex) [0.7,0.1,0.2]\n","    \n","    Returns:\n","        Train / Val / Test dataframe (tuple)\n","    \"\"\"\n","    train_frac, val_frac, test_frac = frac \n","\n","    # Test 데이터 random sampling\n","    test = df.sample(frac = test_frac, replace = False, random_state = fold_seed)\n","    train_val = df[~df.index.isin(test.index)] # Train & Validation 데이터 \n","\n","    # Validation 데이터 random sampling\n","    val = train_val.sample(frac = val_frac/(1-test_frac), replace = False, random_state = 1)\n","    train = train_val[~train_val.index.isin(val.index)] # Train 데이터\n","    \n","    return train, val, test"],"metadata":{"id":"r32HI1aZJ7sV","executionInfo":{"status":"ok","timestamp":1667801311000,"user_tz":-540,"elapsed":1,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def process_data(df, seed, frac):\n","    \n","    # epitope 데이터 중 중복되지 않는 것만 processing\n","    AA = pd.Series(df['antigen'].unique()).apply(lambda x: trans_protein(x, max_seq_epitope))\n","    # raw epitope : processed epitope \n","    AA_dict = dict(zip(df['antigen'].unique(), AA))\n","    # 전체 데이터 processing\n","    df['antigen_processed'] = [AA_dict[i] for i in df['antigen']]\n","\n","    # HLA seq 데이터 중 중복되지 않는 것만 processing\n","    AA = pd.Series(neo[\"full_seq\"].unique()).apply(hla2emb_encoder)\n","    # HLA seq : BPE encoded seq 딕셔너리 \n","    AA_dict = dict(zip(neo[\"full_seq\"].unique(), AA))\n","    # 전체 데이터 processing\n","    neo[\"hla_processed\"] = [AA_dict[i] for i in neo[\"full_seq\"]]\n","\n","    train, val, test = create_fold(df, seed, frac)\n","\n","    return train, val, test\n"],"metadata":{"id":"TAQh5vqygl7j","executionInfo":{"status":"ok","timestamp":1667801311434,"user_tz":-540,"elapsed":2,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["train, val, test = process_data(neo, 22, [0.7,0.1,0.2])"],"metadata":{"id":"8rXkzkk6kVm0","executionInfo":{"status":"ok","timestamp":1667801314130,"user_tz":-540,"elapsed":2351,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def protein_2_embed(x):\n","    return enc_protein.transform(np.array(x).reshape(-1,1)).toarray().T"],"metadata":{"id":"TC0ueTe9gUpB","executionInfo":{"status":"ok","timestamp":1667801314131,"user_tz":-540,"elapsed":5,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["# Torch DataSet & DataLoader"],"metadata":{"id":"qEkESmhAd3Ts"}},{"cell_type":"code","execution_count":25,"metadata":{"id":"prO26z1nFdlc","executionInfo":{"status":"ok","timestamp":1667801314131,"user_tz":-540,"elapsed":5,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"outputs":[],"source":["class data_process_loader(Dataset):\n","    def __init__(self, df):\n","        \"\"\"\n","        Args:\n","            df: Paired drug - protein - affinity dataframe\n","        \"\"\"\n","        self.df = df\n","\n","    def __len__(self):\n","        \"\"\"샘플 개수\n","        \"\"\"\n","        return self.df.shape[0] \n","\n","    def __getitem__(self, index):\n","        # Epitope\n","        v_e = self.df.iloc[index]['antigen_processed'] \n","        v_e = protein_2_embed(v_e) \n","\n","        # HLA seq \n","        v_h = self.df.iloc[index]['hla_processed'] \n","        # v_h = protein_2_embed(v_h) \n","\n","        # Binding affinity (label)\n","        y = self.df.iloc[index]['label'] \n","\n","        return v_e, v_h, y\n"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"2aLy2URNFgKQ","executionInfo":{"status":"ok","timestamp":1667801314131,"user_tz":-540,"elapsed":5,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"outputs":[],"source":["train_dataset = data_process_loader(train)\n","val_dataset = data_process_loader(val)\n","test_dataset = data_process_loader(test)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1667801314131,"user":{"displayName":"seungho cook","userId":"04623047230260438237"},"user_tz":-540},"id":"fnLMM2BVR99D","outputId":"8884574d-07de-4a47-878a-ba1ca9212e35"},"outputs":[{"output_type":"stream","name":"stdout","text":["(26, 12)\n","(366,)\n","(366,)\n","1.0\n"]}],"source":["# Dataset 확인 해보기 \n","\n","for (v_e, v_h, y) in train_dataset:\n","    print(v_e.shape)\n","    print(v_h[0].shape)\n","    print(v_h[1].shape)\n","    print(y)\n","    break"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"hxRGDooeSmuI","executionInfo":{"status":"ok","timestamp":1667801314132,"user_tz":-540,"elapsed":4,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"outputs":[],"source":["# DataLoader 파라미터\n","\n","params = {'batch_size': 256,\n","            'shuffle': True,\n","            'num_workers': 1,\n","            'drop_last': False}"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"fDs5SamDSoce","executionInfo":{"status":"ok","timestamp":1667801314132,"user_tz":-540,"elapsed":4,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"outputs":[],"source":["# Mini-batch 학습을 위한 DataLoader\n","\n","training_generator = DataLoader(train_dataset, **params)\n","valid_generator = DataLoader(val_dataset, **params)\n","test_generator = DataLoader(test_dataset, **params)\n"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1267,"status":"ok","timestamp":1667801315395,"user":{"displayName":"seungho cook","userId":"04623047230260438237"},"user_tz":-540},"id":"I2YtcYgQSqn8","outputId":"e4db7557-27f4-4d9f-ccd7-1838425432bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([256, 26, 12])\n","torch.Size([256, 366])\n","torch.Size([256, 366])\n","tensor([0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n","        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n","        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n","        1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n","        1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n","        0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.,\n","        0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1.,\n","        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n","        1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n","        1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n","        0., 0., 0., 0.], dtype=torch.float64)\n"]}],"source":["# Dataloader 확인해보기 \n","\n","for (v_e, v_h, y) in training_generator:\n","    print(v_e.shape)\n","    print(v_h[0].shape)\n","    print(v_h[1].shape)\n","    print(y)\n","    break"]},{"cell_type":"code","source":["\n","for (v_e, v_h, y) in valid_generator:\n","    print(v_e.shape)\n","    print(v_h[0].shape)\n","    print(v_h[1].shape)\n","    print(y)\n","    break"],"metadata":{"id":"OFwrh7svdQWQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667801316252,"user_tz":-540,"elapsed":858,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}},"outputId":"55362181-a200-42af-f246-48362122777f"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([256, 26, 12])\n","torch.Size([256, 366])\n","torch.Size([256, 366])\n","tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n","        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n","        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n","        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n","        1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n","        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n","        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n","        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n","        0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n","        1., 1., 0., 0.], dtype=torch.float64)\n"]}]},{"cell_type":"code","source":["for (v_e, v_h, y) in test_generator:\n","    print(v_e.shape)\n","    print(v_h[0].shape)\n","    print(v_h[1].shape)\n","    print(y)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bvTgbn8S4c-_","executionInfo":{"status":"ok","timestamp":1667801317260,"user_tz":-540,"elapsed":1010,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}},"outputId":"ee26afe3-b26e-4260-807d-50f60096b69b"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([256, 26, 12])\n","torch.Size([256, 366])\n","torch.Size([256, 366])\n","tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,\n","        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n","        0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n","        1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n","        0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n","        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n","        1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n","        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n","        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n","        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n","        1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n","        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n","        0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n","        0., 0., 0., 1.], dtype=torch.float64)\n"]}]},{"cell_type":"markdown","source":["# 모델 학습 (Training)"],"metadata":{"id":"PG95FRBmdQz_"}},{"cell_type":"markdown","source":["### 모델 설정 및 선언\n"],"metadata":{"id":"uEcJQ2-Vd9BZ"}},{"cell_type":"code","execution_count":33,"metadata":{"id":"gXcbnyJ8FIhZ","executionInfo":{"status":"ok","timestamp":1667801317260,"user_tz":-540,"elapsed":2,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"outputs":[],"source":["# 모델 설정 값\n","\n","config = {\n","    # epitope 설정 (CNN)\n","    \"cnn_epitope_filters\" : [32,64,96],\n","    \"cnn_epitope_kernels\" : [3,3,3],\n","    'hidden_dim_epitope': 128, \n","    'max_seq_epitope' : max_seq_epitope,\n","\n","    # HLA (tranformer)\n","    'input_dim_hla': 4114, # subword vocab 크기\n","    'hidden_dim_hla': 64, # transformer embedding 크기\n","    'transformer_attention_probs_dropout': 0.1, # self-attention 연산 과정에서 적용되는 dropout \n","    'transformer_dropout_rate': 0.1, # word embedding - layer norm 이 후 적용되는 dropout\n","    'transformer_emb_size': 64, # word embedding 후 크기\n","    'transformer_hidden_dropout_rate': 0.1, # MLP에서 적용되는 dropout\n","    'transformer_intermediate_size': 256, # self-attention 이 후 MLP\n","    'transformer_n_layer': 2, # transformer 인코더 개수\n","    'transformer_num_attention_heads': 4, # self attention 시 head 개수\n","    \n","    # classifier\n","    'cls_hidden_dims': [1024, 1024, 512], \n","    }"]},{"cell_type":"markdown","source":["### CNN embedding"],"metadata":{"id":"XGJqqggaVeq3"}},{"cell_type":"code","execution_count":34,"metadata":{"id":"DtQlnkacFMxF","executionInfo":{"status":"ok","timestamp":1667801317260,"user_tz":-540,"elapsed":2,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"outputs":[],"source":["class CNN(nn.Sequential):\n","    def __init__(self, encoding, **config):\n","        super(CNN, self).__init__()\n","\n","        in_ch = [26] + config[f'cnn_{encoding}_filters']\n","        kernels = config[f'cnn_{encoding}_kernels']\n","        layer_size = len(config[f'cnn_{encoding}_filters'])\n","\n","        self.conv = nn.ModuleList([nn.Conv1d(in_channels = in_ch[i], \n","                                    out_channels = in_ch[i+1], \n","                                    kernel_size = kernels[i]) for i in range(layer_size)])\n","        \n","        self.conv = self.conv.double()\n","\n","        max_seq = config[f'max_seq_{encoding}']\n","        n_size_d = self._get_conv_output((26, max_seq))\n","        self.fc1 = nn.Linear(n_size_d, config[f'hidden_dim_{encoding}'])\n","\n","    def _get_conv_output(self, shape):\n","        bs = 1\n","        input = Variable(torch.rand(bs, *shape))\n","        output_feat = self._forward_features(input.double())\n","        n_size = output_feat.data.view(bs, -1).size(1)\n","        return n_size\n","\n","    def _forward_features(self, x):\n","        for l in self.conv:\n","            x = F.relu(l(x))\n","        x = F.adaptive_max_pool1d(x, output_size=1)\n","        return x\n","\n","    def forward(self, v):\n","        v = self._forward_features(v.double())\n","        v = v.view(v.size(0), -1)\n","        v = self.fc1(v.float())\n","        return v"]},{"cell_type":"code","source":[],"metadata":{"id":"taswWAh2ZfyH","executionInfo":{"status":"ok","timestamp":1667801317260,"user_tz":-540,"elapsed":2,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["### Transformer embedding"],"metadata":{"id":"nyXgFYoNZgKZ"}},{"cell_type":"code","source":["import copy\n","import math\n","import collections"],"metadata":{"id":"cAm6dCW6WOWM","executionInfo":{"status":"ok","timestamp":1667801317260,"user_tz":-540,"elapsed":2,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["**Word embedding과 postional encodding**\n","\n","\n","---\n","\n","\n","![](https://drive.google.com/uc?export=view&id=14UwLW9eQf5zDPznytq3La1ylv75xFq1O)\n"],"metadata":{"id":"38s8tqDgWvr5"}},{"cell_type":"code","source":["class LayerNorm(nn.Module):\n","    \"\"\"word embedding 이 후 적용되는 layer normalization\n","    \"\"\"\n","    def __init__(self, hidden_size, variance_epsilon=1e-12):\n","\n","        super(LayerNorm, self).__init__()\n","        self.gamma = nn.Parameter(torch.ones(hidden_size))\n","        self.beta = nn.Parameter(torch.zeros(hidden_size))\n","        self.variance_epsilon = variance_epsilon\n","\n","    def forward(self, x):\n","        u = x.mean(-1, keepdim=True)\n","        s = (x - u).pow(2).mean(-1, keepdim=True)\n","        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n","        return self.gamma * x + self.beta\n","\n","\n","class Embeddings(nn.Module):\n","    \"\"\"Construct the embeddings from protein/target, position embeddings.\n","    \"\"\"\n","    def __init__(self, vocab_size, hidden_size, max_position_size, dropout_rate):\n","        \"\"\"\n","        Args:\n","            vocab_size: int. subword vocab 크기 \n","            hidden_size: int. word embedding 이 후 사이즈\n","            max_postion_size: int. 한 sequence 내에서 가질 수 있는 postion 가짓수 (== sequence size) \n","            dropout_rate: float. embedding 이 후 dropout prob. [0, 1]\n","        \"\"\"\n","        super(Embeddings, self).__init__()\n","        self.word_embeddings = nn.Embedding(vocab_size, hidden_size) \n","        self.position_embeddings = nn.Embedding(max_position_size, hidden_size)\n","\n","        self.LayerNorm = LayerNorm(hidden_size)\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","    def forward(self, input_ids):\n","        seq_length = input_ids.size(1) # input squence 크기\n","        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device) # [0, ... ,input sequence size] \n","        position_ids = position_ids.unsqueeze(0).expand_as(input_ids) # (sequence_size, ) -> (batch size, sequence_size) \n","        \n","        words_embeddings = self.word_embeddings(input_ids) # (batch size, sequence_size) -> (batch size, sequence_size, hidden_size) \n","        position_embeddings = self.position_embeddings(position_ids) # (batch size, sequence_size) -> (batch size, sequence_size, hidden_size)\n","\n","        # input embedding 에 postional encodding 더해주기\n","        embeddings = words_embeddings + position_embeddings \n","        # Layer normalizaton\n","        embeddings = self.LayerNorm(embeddings)\n","        # dropout 적용 \n","        embeddings = self.dropout(embeddings) \n","        return embeddings\n"," "],"metadata":{"id":"W36akwTkWO7d","executionInfo":{"status":"ok","timestamp":1667801317260,"user_tz":-540,"elapsed":2,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["**Self-attention block**\n","\n","---\n","\n","![](https://drive.google.com/uc?export=view&id=1qP1nH5NKTtfEHrp9xhacYcDujCCZo2C6)\n","\n"],"metadata":{"id":"cfZXjdidXkEn"}},{"cell_type":"code","source":["class SelfAttention(nn.Module):\n","    \"\"\"Query, Key, Value matrix를 이용해 multi-head self-attention 수행하기\n","    \"\"\"\n","    def __init__(self, hidden_size, num_attention_heads, attention_probs_dropout_prob):\n","        \"\"\"\n","        Args:\n","            hidden_size: int; word embedding 사이즈\n","            num_attention_heads: int; self-attention(SA) 시 head 개수\n","            attention_probs_dropout_prob: float; SA 이 후 dropout 확률\n","        \"\"\"\n","        \n","        super(SelfAttention, self).__init__()\n","        if hidden_size % num_attention_heads != 0:\n","            # head의 개수가 hidden_size의 약수가 아니면 오류 출력\n","            raise ValueError(\n","                \"The hidden size (%d) is not a multiple of the number of attention \"\n","                \"heads (%d)\" % (hidden_size, num_attention_heads))\n","        \n","        self.num_attention_heads = num_attention_heads # MSA에서 head 개수\n","        self.attention_head_size = int(hidden_size / num_attention_heads) # 각 헤드에서 query, key, value 차원 크기\n","        self.all_head_size = hidden_size # attention_head_size * num_attention_heads\n","\n","        # Query, Key, Value parameter 생성 (hidden_size x (attention_head_size * num_attention_heads))\n","        self.query = nn.Linear(hidden_size, self.all_head_size) \n","        self.key = nn.Linear(hidden_size, self.all_head_size)\n","        self.value = nn.Linear(hidden_size, self.all_head_size)\n","        \n","        self.dropout = nn.Dropout(attention_probs_dropout_prob)\n","\n","    def transpose_for_scores(self, x):\n","        \"\"\"self attention 수행을 위해 permutation 진행\n","        \"\"\"\n","        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size) # (batch_size x vocab_size x num_attention_heads x attention_head_size)\n","        x = x.view(*new_x_shape)\n","        return x.permute(0, 2, 1, 3) # (batch_size x num_attention_heads x vocab_size  x attention_head_size)\n","\n","    def forward(self, hidden_states, attention_mask):\n","        # 모든 head의 query, key, value matrix 한번에 생성하기\n","        mixed_query_layer = self.query(hidden_states)\n","        mixed_key_layer = self.key(hidden_states)\n","        mixed_value_layer = self.value(hidden_states)\n","\n","        # 헤드 별로 qurey, key, value matrix 나누기\n","        query_layer = self.transpose_for_scores(mixed_query_layer)\n","        key_layer = self.transpose_for_scores(mixed_key_layer)\n","        value_layer = self.transpose_for_scores(mixed_value_layer)\n","\n","        # query, key matrix 곱으로 attention scores 구하기\n","        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n","        # attention_head_size로 scaling\n","        attention_scores = attention_scores / math.sqrt(self.attention_head_size) \n","        # attention mask 값 더하기 (masking 할 부분에 매우 작은 음수 값 더해주기)\n","        attention_scores = attention_scores + attention_mask\n","\n","        # softmax를 이용하여 attention score [0,1]의 값으로 만들기\n","        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n","\n","        # self attention 이 후 dropout \n","        attention_probs = self.dropout(attention_probs)\n","\n","        # [0,1]의 attention score로 각 토큰 value의 가중합 구하기 \n","        context_layer = torch.matmul(attention_probs, value_layer)\n","\n","        context_layer = context_layer.permute(0, 2, 1, 3).contiguous() # (batch_size x vocab_size x num_attention_heads x attention_head_size)\n","        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,) # (batch_size x vocab_size x all_head_size)\n","        context_layer = context_layer.view(*new_context_layer_shape)\n","\n","        return context_layer\n","    \n","\n","class SelfOutput(nn.Module):\n","    \"\"\"Self-attention 이 후 multi layer perceptron\n","    \"\"\"\n","    def __init__(self, hidden_size, hidden_dropout_prob):\n","        super(SelfOutput, self).__init__()\n","        self.dense = nn.Linear(hidden_size, hidden_size)\n","        self.LayerNorm = LayerNorm(hidden_size)\n","        self.dropout = nn.Dropout(hidden_dropout_prob)\n","\n","    def forward(self, hidden_states, input_tensor):\n","        hidden_states = self.dense(hidden_states)\n","        hidden_states = self.dropout(hidden_states)\n","        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n","        return hidden_states    \n","    \n","    \n","class Attention(nn.Module):\n","    \"\"\"Self attention + MLP\n","    \"\"\"\n","    def __init__(self, hidden_size, num_attention_heads, attention_probs_dropout_prob, hidden_dropout_prob):\n","        super(Attention, self).__init__()\n","        self.self_attention = SelfAttention(hidden_size, num_attention_heads, attention_probs_dropout_prob)\n","        self.self_output = SelfOutput(hidden_size, hidden_dropout_prob)\n","\n","    def forward(self, input_tensor, attention_mask):\n","        self_output = self.self_attention(input_tensor, attention_mask)\n","        attention_output = self.self_output(self_output, input_tensor)\n","        return attention_output    \n"],"metadata":{"id":"Tmy-K89VTOo-","executionInfo":{"status":"ok","timestamp":1667801317709,"user_tz":-540,"elapsed":1,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JuPd0CfjYZma","executionInfo":{"status":"ok","timestamp":1667801318122,"user_tz":-540,"elapsed":2,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["**MLP embedding** \n","\n","---\n","\n"],"metadata":{"id":"BXqg0HkxYaOn"}},{"cell_type":"code","source":["class Intermediate(nn.Module):\n","    \"\"\"SA 이 후 Non-linear layers\n","    \"\"\"\n","    def __init__(self, hidden_size, intermediate_size):\n","        super(Intermediate, self).__init__()\n","        self.dense = nn.Linear(hidden_size, intermediate_size)\n","\n","    def forward(self, hidden_states):   \n","        hidden_states = self.dense(hidden_states)\n","        hidden_states = F.relu(hidden_states)\n","        return hidden_states\n","\n","class Output(nn.Module):\n","    \"\"\" 최종 linear embedding\n","    \"\"\"\n","    def __init__(self, intermediate_size, hidden_size, hidden_dropout_prob):\n","        super(Output, self).__init__()\n","        self.dense = nn.Linear(intermediate_size, hidden_size)\n","        self.LayerNorm = LayerNorm(hidden_size)\n","        self.dropout = nn.Dropout(hidden_dropout_prob)\n","\n","    def forward(self, hidden_states, input_tensor):\n","        hidden_states = self.dense(hidden_states)\n","        hidden_states = self.dropout(hidden_states)\n","        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n","        return hidden_states"],"metadata":{"id":"wB0MrgyRopLB","executionInfo":{"status":"ok","timestamp":1667801318122,"user_tz":-540,"elapsed":2,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cabFpGdXotKv","executionInfo":{"status":"ok","timestamp":1667801318123,"user_tz":-540,"elapsed":2,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["**Self attention block과 MLP를 합쳐 encoder 만들기**\n","\n","---\n","\n"],"metadata":{"id":"VIEFHkPEYsVn"}},{"cell_type":"code","source":["# SA + MLP\n","class Encoder(nn.Module):\n","    def __init__(self, hidden_size, intermediate_size, num_attention_heads, attention_probs_dropout_prob, hidden_dropout_prob):\n","        super(Encoder, self).__init__()\n","        self.attention = Attention(hidden_size, num_attention_heads, attention_probs_dropout_prob, hidden_dropout_prob)\n","        self.intermediate = Intermediate(hidden_size, intermediate_size)\n","        self.output = Output(intermediate_size, hidden_size, hidden_dropout_prob)\n","\n","    def forward(self, hidden_states, attention_mask):\n","        attention_output = self.attention(hidden_states, attention_mask)\n","        intermediate_output = self.intermediate(attention_output)\n","        layer_output = self.output(intermediate_output, attention_output)\n","        return layer_output    \n","\n","# n_layer 만큼 encoder 쌓기\n","class Encoder_MultipleLayers(nn.Module):\n","    def __init__(self, n_layer, hidden_size, intermediate_size, num_attention_heads, attention_probs_dropout_prob, hidden_dropout_prob):\n","        super(Encoder_MultipleLayers, self).__init__()\n","        layer = Encoder(hidden_size, intermediate_size, num_attention_heads, attention_probs_dropout_prob, hidden_dropout_prob)\n","        self.layer = nn.ModuleList([copy.deepcopy(layer) for _ in range(n_layer)])    \n","\n","    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True):\n","        all_encoder_layers = []\n","        for layer_module in self.layer:\n","            hidden_states = layer_module(hidden_states, attention_mask)\n","            #if output_all_encoded_layers:\n","            #    all_encoder_layers.append(hidden_states)\n","        #if not output_all_encoded_layers:\n","        #    all_encoder_layers.append(hidden_states)\n","        return hidden_states\n","    "],"metadata":{"id":"5r-2S3YxYrJ3","executionInfo":{"status":"ok","timestamp":1667801319292,"user_tz":-540,"elapsed":1,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["**Transformer \bembedder**"],"metadata":{"id":"kSxNmVESZmle"}},{"cell_type":"code","source":["class transformer(nn.Sequential):\n","    def __init__(self, encoding, **config):\n","        super(transformer, self).__init__()\n","\t\t\n","        if encoding == 'hla':\n","            self.emb = Embeddings(config['input_dim_hla'], config['transformer_emb_size'], 366, config['transformer_dropout_rate'])\n","            self.encoder = Encoder_MultipleLayers(config['transformer_n_layer'], \n","                                                config['transformer_emb_size'], \n","                                                config['transformer_intermediate_size'], \n","                                                config['transformer_num_attention_heads'],\n","                                                config['transformer_attention_probs_dropout'],\n","                                                config['transformer_hidden_dropout_rate'])\n","\n","    ### parameter v (tuple of length 2) is from utils.drug2emb_encoder \n","    def forward(self, v): \n","        e = v[0].long().to(device) # subword encoding 된 input\n","        e_mask = v[1].long().to(device) # masking table (0 또는 1 값만 가짐)\n","        ex_e_mask = e_mask.unsqueeze(1).unsqueeze(2)  \n","        ex_e_mask = (1.0 - ex_e_mask) * -10000.0 # (if 0 -> 매우 작은 음수 값, else -> 0 )\n","\n","        emb = self.emb(e) # word embedding - postional encodding - layer normalization 진행\n","        encoded_layers = self.encoder(emb.float(), ex_e_mask.float()) # self-attention block + MLP embedding layer\n","        return encoded_layers[:,0] "],"metadata":{"id":"UN0L8V4OU6P1","executionInfo":{"status":"ok","timestamp":1667801319705,"user_tz":-540,"elapsed":2,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["### Embedding 된 vector를 이용하여 최종 예측에 활용되는 classifier"],"metadata":{"id":"wUmtg1PqZ46H"}},{"cell_type":"code","execution_count":41,"metadata":{"id":"FIm2ptJfS3ND","executionInfo":{"status":"ok","timestamp":1667801319705,"user_tz":-540,"elapsed":2,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"outputs":[],"source":["class Classifier(nn.Sequential):\n","\t\"\"\"임베딩 된 epitope와 HLA 이용하여 classificaion\n","\t\"\"\"\n","\tdef __init__(self, model_epitope, model_hla, **config):\n","\t\t\"\"\"\n","\t\tArgs:\n","\t\t\tmodel_epitope: epitope emedding 모델\n","\t\t\tmodel_hla: hla emedding 모델\n","\t\t\tconfig: 모델 설정 값\n","\t\t\"\"\"\n","\t\tsuper(Classifier, self).__init__()\n","\n","\t\tself.input_dim_epitope = config['hidden_dim_epitope'] # epitope feature 사이즈\n","\t\tself.input_dim_hla = config['hidden_dim_hla'] # hla feature 사이즈\n","\n","\t\tself.model_epitope = model_epitope # epitope 임베딩 모델\n","\t\tself.model_hla = model_hla # hla 임베딩 모델\n","\n","\t\tself.dropout = nn.Dropout(0.1) # dropout 적용\n","\n","\t\tself.hidden_dims = config['cls_hidden_dims'] # classifier hidden dimensions\n","\t\tlayer_size = len(self.hidden_dims) + 1 # hidden layer 개수\n","\t\tdims = [self.input_dim_epitope + self.input_dim_hla] + self.hidden_dims + [1] # [\"합쳐진 feature 차원 (epitope + hla), hidden1, hidden2, hidden3, 1 (output layer)] \n","\t\t\n","\t\tself.predictor = nn.ModuleList([nn.Linear(dims[i], dims[i+1]) for i in range(layer_size)]) # classifer layers \n","\n","\tdef forward(self, v_D, v_P):\n","\t\t# epitope/hla 임베딩\n","\t\tv_E = self.model_epitope(v_D)\n","\t\tv_H = self.model_hla(v_P)\n","  \n","\t\t# epitope - hla feature 합치기 \n","\t\tv_f = torch.cat((v_E, v_H), 1)\n","  \n","\t\tfor i, l in enumerate(self.predictor):\n","\t\t\tif i == (len(self.predictor)-1):\n","\t\t\t\t# If last layer,\n","\t\t\t\tv_f = l(v_f)\n","\t\t\telse:\n","\t\t\t\t# If Not last layer, dropout과 ReLU 적용\n","\t\t\t\tv_f = F.relu(self.dropout(l(v_f)))\n","\t\n","\t\treturn v_f\n"]},{"cell_type":"code","source":[],"metadata":{"id":"rLZu-i9saIk6","executionInfo":{"status":"ok","timestamp":1667801319705,"user_tz":-540,"elapsed":2,"user":{"displayName":"seungho cook","userId":"04623047230260438237"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["### 학습 진행"],"metadata":{"id":"LznE7vqsaJA3"}},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1667801319705,"user":{"displayName":"seungho cook","userId":"04623047230260438237"},"user_tz":-540},"id":"X-NOkQN5R5oz","outputId":"ed956799-8eb5-4746-db31-45da21e7aa07"},"outputs":[{"output_type":"stream","name":"stdout","text":["현재 디바이스는 cuda:0 입니다.\n"]}],"source":["# 디바이스 설정\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"현재 디바이스는 {device} 입니다.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1CKJgVNS53F"},"outputs":[],"source":["# model for drug\n","model_epitope = CNN('epitope', **config)\n","\n","# model for protein\n","model_hla = transformer('hla', **config)\n","\n","# classifier\n","model = Classifier(model_epitope, model_hla, **config)\n","\n","model = model.to(device) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wWfLytzaZ_Bu"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPi4HEWAZ_Nx"},"outputs":[],"source":["from prettytable import PrettyTable\n","from time import time\n","\n","from sklearn.metrics import mean_squared_error, roc_auc_score, average_precision_score, f1_score, log_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wpBp0JcSaAcr"},"outputs":[],"source":["# 하이퍼 파라미터(hyper parameter)\n","\n","learning_rate = 0.001\n","weight_decay  = 0.00001\n","train_epoch   = 20"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v6srIPy3aCCu"},"outputs":[],"source":["# 옵티마이저 선언\n","opt = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay) # Adam optimizer\n","\n","# 손실 함수 선언\n","loss_fct = torch.nn.BCELoss()\n","\n","# 시그모이드(sigmoid) 함수\n","sigmoid = torch.nn.Sigmoid() "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u4-pKvt2aDdn"},"outputs":[],"source":["def get_metrics(y_label, y_pred):\n","    outputs = np.asarray([1 if i else 0 for i in (np.asarray(y_pred) >= 0.5)]) \n","    \n","    # metrics\n","    auc = roc_auc_score(y_label, y_pred) # AUC \n","    auprc = average_precision_score(y_label, y_pred) # Average Precision\n","    f1 = f1_score(y_label, outputs) # F1 score\n","    lloss = log_loss(y_label, outputs) # cross-entropy loss \n","\n","    return auc, auprc, f1, lloss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KrbEn5PFaFEH"},"outputs":[],"source":["loss_history = [] \n","\n","max_auc = 0 # 최고 AUC 저장\n","model_max = copy.deepcopy(model) # 최고 AUC 저장\n","\n","valid_metric_record = [] # 각 metrics 저장\n","valid_metric_header = [\"# epoch\"] \n","valid_metric_header.extend([\"AUROC\", \"AUPRC\", \"F1\"])\n","\n","table = PrettyTable(valid_metric_header)\n","\n","float2str = lambda x:'%0.4f'%x  # float 자료 형 str로 만들기 (소숫점 4자리까지)\n","\n","print('--- Go for Training ---')\n","t_start = time() \n","\n","\n","for epoch in range(train_epoch):\n","    # Training\n","    model.train() \n","\n","    for i, (v_e, v_h, label) in enumerate(training_generator):\n","        v_h = tuple(map(lambda x: x.float().to(device), v_h))\n","        v_e = v_e.float().to(device) \n","        \n","        # 순전파 (forward-pass)\n","        score = model(v_e, v_h)\n","        label = Variable(torch.from_numpy(np.array(label)).float()).to(device) # label numpy -> torch tensor\n","        \n","        # 모델 아웃풋 score -> probability\n","        n = torch.squeeze(sigmoid(score), 1)\n","        \n","        # 손실 값(loss) 계산\n","        loss = loss_fct(n, label)            \n","        loss_history.append(loss.item()) # loss 기록\n","\n","        opt.zero_grad() # gradient 초기화\n","        loss.backward() # back propagation\n","        opt.step() # parameter 업데이트\n","\n","    # Validation\n","    model.eval()\n","    with torch.set_grad_enabled(False):\n","        y_pred = []\n","        y_label = []\n","\n","        for i, (v_e, v_h, label) in enumerate(valid_generator):\n","            v_h = tuple(map(lambda x: x.float().to(device), v_h))\n","            v_e = v_e.float().to(device) \n","\n","            # 순전파 (forward-pass)\n","            score = model(v_e, v_h)\n","            \n","            logits = torch.squeeze(sigmoid(score)).detach().cpu().numpy() # 예측 확률\n","            label_ids = label.to('cpu').numpy() # 참 값 \n","\n","            y_label = y_label + label_ids.flatten().tolist()\n","            y_pred = y_pred + logits.flatten().tolist() \n","\n","    # 예측 값 \n","    outputs = np.asarray([1 if i else 0 for i in (np.asarray(y_pred) >= 0.5)]) \n","\n","    # model evaluation\n","    auc, auprc, f1, lloss = get_metrics(y_label, y_pred)\n","\n","    lst = [\"epoch \" + str(epoch)] + list(map(float2str,[auc, auprc, f1]))\n","    valid_metric_record.append(lst)\n","\n","    if auc > max_auc:\n","        # 이전 epoch 보다 AUC 좋아지면 model_max, max_auc 갱신\n","        model_max = copy.deepcopy(model)\n","        max_auc = auc   \n","\n","    print('Validation at Epoch '+ str(epoch + 1) + ', AUROC: ' + str(auc)[:7] + \\\n","            ' , AUPRC: ' + str(auprc)[:7] + ' , F1: '+str(f1)[:7] + ' , Cross-entropy Loss: ' + \\\n","            str(lloss)[:7])\n","    \n","    \n","    table.add_row(lst)\n","\n"]},{"cell_type":"markdown","source":["# 모델 테스트 (Test)"],"metadata":{"id":"VYzvEtDuc22h"}},{"cell_type":"code","source":["model = model_max \n","model.eval()\n","\n","y_pred = []\n","y_label = []\n","y_outputs = []\n","\n","for i, (v_e, v_h, label) in enumerate(test_generator):\n","    v_h = tuple(map(lambda x: x.float().to(device), v_h))\n","    v_e = v_e.float().to(device) \n","    \n","    # 순전파(forward-pass)\n","    score = model(v_e, v_h) \n","    logits = torch.squeeze(sigmoid(score)).detach().cpu().numpy()\n","\n","    label_ids = label.to('cpu').numpy()\n","    y_label = y_label + label_ids.flatten().tolist()\n","    y_pred = y_pred + logits.flatten().tolist()\n","    outputs = np.asarray([1 if i else 0 for i in (np.asarray(y_pred) >= 0.5)])\n","\n","    y_outputs.append(outputs)\n"],"metadata":{"id":"38K9RBJgc5bC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model evaluation\n","auc, auprc, f1, lloss = get_metrics(y_label, y_pred)\n","\n","print('Test result - ' + ', AUROC: ' + str(auc)[:7] + ' , AUPRC: ' + str(auprc)[:7] + ' , F1: '+str(f1)[:7] + ' , Cross-entropy Loss: ' + str(loss)[:7])"],"metadata":{"id":"pVHDhnfEc7w5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def roc_curve(y_pred, y_label, figure_file, method_name):\n","\t'''ROC 커브 그리기\n","\n","\tArgs:\n","\t\ty_pred: 예측 확률 값이 담긴 리스트 [0,1]\n","\t\ty_label: 참 값 (0/1)\n","\t'''\n","\n","\timport matplotlib.pyplot as plt\n","\tfrom sklearn.metrics import roc_curve, auc\n","\tfrom sklearn.metrics import roc_auc_score\n","\n","\ty_label = np.array(y_label)\n","\ty_pred = np.array(y_pred)\t\n"," \n","\tfpr = dict()\n","\ttpr = dict() \n","\troc_auc = dict()\n"," \n","\tfpr[0], tpr[0], _ = roc_curve(y_label, y_pred) # FPR / TPR 구하기\n","\troc_auc[0] = auc(fpr[0], tpr[0]) # AUC 구하기\n","\t\n","\t# ROC 커브 그리기\n","\tlw = 2\n","\tplt.plot(fpr[0], tpr[0],\n","         lw=lw, label= method_name + ' (area = %0.2f)' % roc_auc[0])\n","\tplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n","\tplt.xlim([0.0, 1.0])\n","\tplt.ylim([0.0, 1.05])\n","\tfontsize = 14\n","\tplt.xlabel('False Positive Rate', fontsize = fontsize)\n","\tplt.ylabel('True Positive Rate', fontsize = fontsize)\n","\tplt.title('Receiver Operating Characteristic Curve')\n","\tplt.legend(loc=\"lower right\")\n","\tplt.savefig(figure_file)\n"," \n","\n","def prauc_curve(y_pred, y_label, figure_file, method_name):\n","\t'''Precision-Recall 커브 그리기\n","\t\n","\tArgs:\n","\t\ty_pred: 예측 확률 값이 담긴 리스트 [0,1]\n","\t\ty_label: 참 값 (0/1)\n","\t'''\n","\timport matplotlib.pyplot as plt\n","\tfrom sklearn.metrics import precision_recall_curve, average_precision_score\n","\tfrom sklearn.metrics import f1_score\n","\tfrom sklearn.metrics import auc\n","\n","\tlr_precision, lr_recall, _ = precision_recall_curve(y_label, y_pred) # precision, recall 구하기\n","\t\n","\t# 커브 그리기\n","\tplt.plot(lr_recall, lr_precision, lw = 2, label= method_name + ' (area = %0.2f)' % average_precision_score(y_label, y_pred))\n","\tfontsize = 14\n","\tplt.xlabel('Recall', fontsize = fontsize)\n","\tplt.ylabel('Precision', fontsize = fontsize)\n","\tplt.title('Precision Recall Curve')\n","\tplt.legend()\n","\tplt.savefig(figure_file)\n"],"metadata":{"id":"vPHOI9_5c-cY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["roc_curve(y_pred, y_label, \"NeoAntigen.png\", \"NeoAntigen\")"],"metadata":{"id":"MfMfd1h_enAt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prauc_curve(y_pred, y_label, \"NeoAntigen.png\", \"NeoAntigen\")"],"metadata":{"id":"ZjgXUdPdeohh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BSqxD6L5tIko"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}