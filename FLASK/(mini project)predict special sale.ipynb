{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>busy_day</th>\n",
       "      <th>high_temperature</th>\n",
       "      <th>special_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-08-05</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-08-06</td>\n",
       "      <td>Tue</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-08-07</td>\n",
       "      <td>Wed</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-08-08</td>\n",
       "      <td>Thu</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-08-09</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2002-08-10</td>\n",
       "      <td>Sat</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2002-08-11</td>\n",
       "      <td>Sun</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2002-08-12</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>Tue</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2002-08-14</td>\n",
       "      <td>Wed</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2002-08-15</td>\n",
       "      <td>Thu</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2002-08-16</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2002-08-17</td>\n",
       "      <td>Sat</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2002-08-18</td>\n",
       "      <td>Sun</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2002-08-19</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2002-08-20</td>\n",
       "      <td>Tue</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2002-08-21</td>\n",
       "      <td>Wed</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2002-08-22</td>\n",
       "      <td>Thu</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2002-08-23</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2002-08-24</td>\n",
       "      <td>Sat</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2002-08-25</td>\n",
       "      <td>Sun</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date weekday  busy_day  high_temperature  special_sales\n",
       "0   2002-08-05     Mon         0                28              1\n",
       "1   2002-08-06     Tue         0                24              0\n",
       "2   2002-08-07     Wed         1                26              0\n",
       "3   2002-08-08     Thu         0                24              0\n",
       "4   2002-08-09     Fri         0                23              0\n",
       "5   2002-08-10     Sat         1                28              1\n",
       "6   2002-08-11     Sun         1                24              0\n",
       "7   2002-08-12     Mon         0                26              1\n",
       "8   2002-08-13     Tue         0                25              0\n",
       "9   2002-08-14     Wed         1                28              1\n",
       "10  2002-08-15     Thu         0                21              0\n",
       "11  2002-08-16     Fri         0                22              0\n",
       "12  2002-08-17     Sat         1                27              1\n",
       "13  2002-08-18     Sun         1                26              1\n",
       "14  2002-08-19     Mon         0                26              0\n",
       "15  2002-08-20     Tue         0                21              0\n",
       "16  2002-08-21     Wed         1                21              1\n",
       "17  2002-08-22     Thu         0                27              0\n",
       "18  2002-08-23     Fri         0                23              0\n",
       "19  2002-08-24     Sat         1                22              0\n",
       "20  2002-08-25     Sun         1                24              1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/jmnote/zdata/master/logistic-regression/special-sales.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = df['special_sales']\n",
    "InputFeature = df[['busy_day', 'high_temperature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, activation='linear', input_shape=(2, )))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 13\n",
      "Trainable params: 13\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call-back 함수\n",
    "# CheckPoint: Epoch 마다 validation 성능을 검증하여, best performance 일 경우 저장\n",
    "CP = ModelCheckpoint(filepath='models/-{epoch:03d}-{loss:.4f}-{accuracy:.4f}.hdf5',\n",
    "            monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# Learning Rate 줄여나가기\n",
    "LR = ReduceLROnPlateau(monitor='loss',factor=0.8,patience=3, verbose=1, min_lr=1e-8)\n",
    "\n",
    "CALLBACK = [CP, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.55123, saving model to models\\-001-0.5512-0.7619.hdf5\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.55123\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.5513 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.55123\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00004: loss improved from 0.55123 to 0.55115, saving model to models\\-004-0.5511-0.7619.hdf5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0001801439793780446.\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.55115\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5513 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.55115\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.55115\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00014411518350243568.\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.55115\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00009: loss improved from 0.55115 to 0.55099, saving model to models\\-009-0.5510-0.7619.hdf5\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.55099\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00011: loss improved from 0.55099 to 0.55099, saving model to models\\-011-0.5510-0.7619.hdf5\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.55099\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00011529214680194855.\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.55099\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00014: loss improved from 0.55099 to 0.55087, saving model to models\\-014-0.5509-0.7619.hdf5\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.55087\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.55087\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.55087\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.223371744155885e-05.\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00018: loss improved from 0.55087 to 0.55081, saving model to models\\-018-0.5508-0.7619.hdf5\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.55081\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00020: loss improved from 0.55081 to 0.55078, saving model to models\\-020-0.5508-0.7619.hdf5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 7.378697628155351e-05.\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.55078\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00022: loss improved from 0.55078 to 0.55068, saving model to models\\-022-0.5507-0.7619.hdf5\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.55068\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.55068\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.55068\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 5.9029582189396024e-05.\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.55068\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.55068\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.55068\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.722366575151682e-05.\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.55068\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00030: loss improved from 0.55068 to 0.55066, saving model to models\\-030-0.5507-0.7619.hdf5\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.55066\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 3.777893143706024e-05.\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00032: loss improved from 0.55066 to 0.55064, saving model to models\\-032-0.5506-0.7619.hdf5\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.55064\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.55064\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 3.022314631380141e-05.\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00035: loss improved from 0.55064 to 0.55062, saving model to models\\-035-0.5506-0.7619.hdf5\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.55062\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.55062\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 2.4178516468964517e-05.\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00038: loss improved from 0.55062 to 0.55060, saving model to models\\-038-0.5506-0.7619.hdf5\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5508 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.55060\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.55060\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.9342813175171614e-05.\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00041: loss improved from 0.55060 to 0.55058, saving model to models\\-041-0.5506-0.7619.hdf5\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5507 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.55058\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.55058\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.55058\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.5474250540137293e-05.\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.55058\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.55058\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.55058\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.2379400141071529e-05.\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00048: loss improved from 0.55058 to 0.55056, saving model to models\\-048-0.5506-0.7619.hdf5\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00049: loss improved from 0.55056 to 0.55056, saving model to models\\-049-0.5506-0.7619.hdf5\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.55056\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 9.903519821818919e-06.\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.55056\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00052: loss improved from 0.55056 to 0.55055, saving model to models\\-052-0.5506-0.7619.hdf5\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00053: loss did not improve from 0.55055\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 7.922815711935982e-06.\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00054: loss improved from 0.55055 to 0.55055, saving model to models\\-054-0.5505-0.7619.hdf5\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00055: loss did not improve from 0.55055\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00056: loss did not improve from 0.55055\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 6.338252569548786e-06.\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00057: loss did not improve from 0.55055\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00058: loss did not improve from 0.55055\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00059: loss improved from 0.55055 to 0.55055, saving model to models\\-059-0.5505-0.7619.hdf5\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 5.070602128398605e-06.\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.55055\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00061: loss did not improve from 0.55055\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00062: loss did not improve from 0.55055\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 4.056481702718884e-06.\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00063: loss did not improve from 0.55055\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00064: loss improved from 0.55055 to 0.55055, saving model to models\\-064-0.5505-0.7619.hdf5\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00065: loss did not improve from 0.55055\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 3.2451855076942595e-06.\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00066: loss did not improve from 0.55055\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00067: loss did not improve from 0.55055\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00068: loss did not improve from 0.55055\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 2.596148442535196e-06.\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00069: loss did not improve from 0.55055\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00070: loss improved from 0.55055 to 0.55054, saving model to models\\-070-0.5505-0.7619.hdf5\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00071: loss did not improve from 0.55054\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 2.0769188267877325e-06.\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00072: loss did not improve from 0.55054\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00073: loss did not improve from 0.55054\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00074: loss improved from 0.55054 to 0.55054, saving model to models\\-074-0.5505-0.7619.hdf5\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.6615351341897623e-06.\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00075: loss improved from 0.55054 to 0.55054, saving model to models\\-075-0.5505-0.7619.hdf5\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00076: loss improved from 0.55054 to 0.55054, saving model to models\\-076-0.5505-0.7619.hdf5\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00077: loss did not improve from 0.55054\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1.3292281437315979e-06.\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00078: loss did not improve from 0.55054\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00079: loss did not improve from 0.55054\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00080: loss did not improve from 0.55054\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1.0633824786054903e-06.\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00081: loss improved from 0.55054 to 0.55054, saving model to models\\-081-0.5505-0.7619.hdf5\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00082: loss did not improve from 0.55054\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00083: loss improved from 0.55054 to 0.55054, saving model to models\\-083-0.5505-0.7619.hdf5\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 8.507059646944982e-07.\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00084: loss did not improve from 0.55054\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00085: loss did not improve from 0.55054\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.55054\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 6.805647899454925e-07.\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00087: loss did not improve from 0.55054\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00088: loss improved from 0.55054 to 0.55053, saving model to models\\-088-0.5505-0.7619.hdf5\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00089: loss did not improve from 0.55053\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 5.444518137665e-07.\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00090: loss did not improve from 0.55053\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.55053\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00092: loss did not improve from 0.55053\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 4.3556146920309404e-07.\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00093: loss did not improve from 0.55053\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00094: loss improved from 0.55053 to 0.55053, saving model to models\\-094-0.5505-0.7619.hdf5\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00095: loss did not improve from 0.55053\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 3.4844917990994877e-07.\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00096: loss did not improve from 0.55053\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00097: loss did not improve from 0.55053\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00098: loss did not improve from 0.55053\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 2.78759353022906e-07.\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00099: loss improved from 0.55053 to 0.55053, saving model to models\\-099-0.5505-0.7619.hdf5\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00100: loss improved from 0.55053 to 0.55053, saving model to models\\-100-0.5505-0.7619.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27b796de9a0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=InputFeature, y=Label, epochs=100, shuffle=True, batch_size=3, callbacks=CALLBACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./models/-100-0.5505-0.7619.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8798076923076923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(roc_auc_score(Label, model.predict(InputFeature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask import render_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/sale/<busy_day>/<high_temperature>')\n",
    "def get_auc(busy_day=None, high_temperature=None):\n",
    "    data = pd.DataFrame({\n",
    "        'busy_day': [int(busy_day)],\n",
    "        'high_temperature':[float(high_temperature)]\n",
    "    })\n",
    "    return \"auc: \" + str(model.predict(data)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses (0.0.0.0)\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.55.187:5000 (Press CTRL+C to quit)\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:47] \"GET /sale/1/30 HTTP/1.1\" 200 -\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:47] \"GET /sale/1/30 HTTP/1.1\" 200 -\n",
      "[2022-07-06 17:28:51,697] ERROR in app: Exception on /sale/1/2- [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"C:\\Users\\gmlkd\\AppData\\Local\\Temp\\ipykernel_14396\\4276189752.py\", line 5, in get_auc\n",
      "    'high_temperature':[float(high_temperature)]\n",
      "ValueError: could not convert string to float: '2-'\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:51] \"GET /sale/1/2- HTTP/1.1\" 500 -\n",
      "[2022-07-06 17:28:51,787] ERROR in app: Exception on /sale/1/2- [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"C:\\Users\\gmlkd\\AppData\\Local\\Temp\\ipykernel_14396\\4276189752.py\", line 5, in get_auc\n",
      "    'high_temperature':[float(high_temperature)]\n",
      "ValueError: could not convert string to float: '2-'\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:51] \"GET /sale/1/2- HTTP/1.1\" 500 -\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:54] \"GET /sale/1/20 HTTP/1.1\" 200 -\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:55] \"GET /sale/1/20 HTTP/1.1\" 200 -\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:59] \"GET /sale/0/20 HTTP/1.1\" 200 -\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:59] \"GET /sale/0/20 HTTP/1.1\" 200 -\n",
      "192.168.55.187 - - [06/Jul/2022 17:29:05] \"GET /sale/1/38 HTTP/1.1\" 200 -\n",
      "192.168.55.187 - - [06/Jul/2022 17:29:05] \"GET /sale/1/38 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('fastcampus')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d03f6901b6a42dbe3cd1c26aed86af13911a401140e63ddc3b23a4d593814a4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
