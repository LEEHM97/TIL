{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>busy_day</th>\n",
       "      <th>high_temperature</th>\n",
       "      <th>special_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-08-05</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-08-06</td>\n",
       "      <td>Tue</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-08-07</td>\n",
       "      <td>Wed</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-08-08</td>\n",
       "      <td>Thu</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-08-09</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2002-08-10</td>\n",
       "      <td>Sat</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2002-08-11</td>\n",
       "      <td>Sun</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2002-08-12</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>Tue</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2002-08-14</td>\n",
       "      <td>Wed</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2002-08-15</td>\n",
       "      <td>Thu</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2002-08-16</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2002-08-17</td>\n",
       "      <td>Sat</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2002-08-18</td>\n",
       "      <td>Sun</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2002-08-19</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2002-08-20</td>\n",
       "      <td>Tue</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2002-08-21</td>\n",
       "      <td>Wed</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2002-08-22</td>\n",
       "      <td>Thu</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2002-08-23</td>\n",
       "      <td>Fri</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2002-08-24</td>\n",
       "      <td>Sat</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2002-08-25</td>\n",
       "      <td>Sun</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date weekday  busy_day  high_temperature  special_sales\n",
       "0   2002-08-05     Mon         0                28              1\n",
       "1   2002-08-06     Tue         0                24              0\n",
       "2   2002-08-07     Wed         1                26              0\n",
       "3   2002-08-08     Thu         0                24              0\n",
       "4   2002-08-09     Fri         0                23              0\n",
       "5   2002-08-10     Sat         1                28              1\n",
       "6   2002-08-11     Sun         1                24              0\n",
       "7   2002-08-12     Mon         0                26              1\n",
       "8   2002-08-13     Tue         0                25              0\n",
       "9   2002-08-14     Wed         1                28              1\n",
       "10  2002-08-15     Thu         0                21              0\n",
       "11  2002-08-16     Fri         0                22              0\n",
       "12  2002-08-17     Sat         1                27              1\n",
       "13  2002-08-18     Sun         1                26              1\n",
       "14  2002-08-19     Mon         0                26              0\n",
       "15  2002-08-20     Tue         0                21              0\n",
       "16  2002-08-21     Wed         1                21              1\n",
       "17  2002-08-22     Thu         0                27              0\n",
       "18  2002-08-23     Fri         0                23              0\n",
       "19  2002-08-24     Sat         1                22              0\n",
       "20  2002-08-25     Sun         1                24              1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/jmnote/zdata/master/logistic-regression/special-sales.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = df['special_sales']\n",
    "InputFeature = df[['busy_day', 'high_temperature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, activation='linear', input_shape=(2, )))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 13\n",
      "Trainable params: 13\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call-back 함수\n",
    "# CheckPoint: Epoch 마다 validation 성능을 검증하여, best performance 일 경우 저장\n",
    "CP = ModelCheckpoint(filepath='-{epoch:03d}-{loss:.4f}-{accuracy:.4f}.hdf5',\n",
    "            monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# Learning Rate 줄여나가기\n",
    "LR = ReduceLROnPlateau(monitor='loss',factor=0.8,patience=3, verbose=1, min_lr=1e-8)\n",
    "\n",
    "CALLBACK = [CP, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3739 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.37392, saving model to -001-1.3739-0.6190.hdf5\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0493 - accuracy: 0.5714\n",
      "\n",
      "Epoch 00002: loss improved from 1.37392 to 1.04927, saving model to -002-1.0493-0.5714.hdf5\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8213 - accuracy: 0.3810\n",
      "\n",
      "Epoch 00003: loss improved from 1.04927 to 0.82134, saving model to -003-0.8213-0.3810.hdf5\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00004: loss improved from 0.82134 to 0.68102, saving model to -004-0.6810-0.6190.hdf5\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7503 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.68102\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.68102\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.68102\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00008: loss improved from 0.68102 to 0.66616, saving model to -008-0.6662-0.6190.hdf5\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.66616\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00010: loss improved from 0.66616 to 0.64857, saving model to -010-0.6486-0.6190.hdf5\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.64857\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7254 - accuracy: 0.3333\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.64857\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.7143\n",
      "\n",
      "Epoch 00013: loss improved from 0.64857 to 0.63168, saving model to -013-0.6317-0.7143.hdf5\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.63168\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.6667\n",
      "\n",
      "Epoch 00015: loss improved from 0.63168 to 0.61941, saving model to -015-0.6194-0.6667.hdf5\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6290 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.61941\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00017: loss improved from 0.61941 to 0.61767, saving model to -017-0.6177-0.6190.hdf5\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.61767\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.61767\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.6667\n",
      "\n",
      "Epoch 00020: loss improved from 0.61767 to 0.60102, saving model to -020-0.6010-0.6667.hdf5\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.60102\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.60102\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5973 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00023: loss improved from 0.60102 to 0.59733, saving model to -023-0.5973-0.6190.hdf5\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00024: loss improved from 0.59733 to 0.59332, saving model to -024-0.5933-0.7619.hdf5\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6084 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.59332\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.59332\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.59332\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.006399999558925629.\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.59332\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.59332\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6019 - accuracy: 0.6190\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.59332\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0051199994981288915.\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00031: loss improved from 0.59332 to 0.57757, saving model to -031-0.5776-0.7619.hdf5\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.57757\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.57757\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6667\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.57757\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.004095999523997307.\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00035: loss improved from 0.57757 to 0.57360, saving model to -035-0.5736-0.7619.hdf5\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.57360\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.57360\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00038: loss improved from 0.57360 to 0.57231, saving model to -038-0.5723-0.7619.hdf5\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.57231\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.57231\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00041: loss improved from 0.57231 to 0.56742, saving model to -041-0.5674-0.7619.hdf5\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.56742\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.56742\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.56742\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0032767996191978457.\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00045: loss improved from 0.56742 to 0.56429, saving model to -045-0.5643-0.7619.hdf5\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00046: loss improved from 0.56429 to 0.56050, saving model to -046-0.5605-0.7619.hdf5\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.56050\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.56050\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.56050\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0026214396581053737.\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.56050\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00051: loss improved from 0.56050 to 0.55727, saving model to -051-0.5573-0.7619.hdf5\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00052: loss did not improve from 0.55727\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00053: loss did not improve from 0.55727\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00054: loss did not improve from 0.55727\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0020971518009901048.\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00055: loss did not improve from 0.55727\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00056: loss improved from 0.55727 to 0.55635, saving model to -056-0.5563-0.7619.hdf5\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00057: loss did not improve from 0.55635\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00058: loss did not improve from 0.55635\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00059: loss did not improve from 0.55635\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0016777213662862779.\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.55635\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00061: loss did not improve from 0.55635\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00062: loss did not improve from 0.55635\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0013421771116554739.\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00063: loss did not improve from 0.55635\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00064: loss improved from 0.55635 to 0.55537, saving model to -064-0.5554-0.7619.hdf5\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5537 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00065: loss improved from 0.55537 to 0.55372, saving model to -065-0.5537-0.7619.hdf5\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00066: loss did not improve from 0.55372\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00067: loss did not improve from 0.55372\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00068: loss did not improve from 0.55372\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.001073741726577282.\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00069: loss did not improve from 0.55372\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00070: loss did not improve from 0.55372\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00071: loss did not improve from 0.55372\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0008589933626353742.\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5554 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00072: loss did not improve from 0.55372\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5550 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00073: loss did not improve from 0.55372\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00074: loss did not improve from 0.55372\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0006871947087347508.\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00075: loss did not improve from 0.55372\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00076: loss improved from 0.55372 to 0.55360, saving model to -076-0.5536-0.7619.hdf5\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00077: loss did not improve from 0.55360\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00078: loss improved from 0.55360 to 0.55323, saving model to -078-0.5532-0.7619.hdf5\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00079: loss did not improve from 0.55323\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00080: loss improved from 0.55323 to 0.55311, saving model to -080-0.5531-0.7619.hdf5\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5524 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00081: loss improved from 0.55311 to 0.55237, saving model to -081-0.5524-0.7619.hdf5\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00082: loss did not improve from 0.55237\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5526 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00083: loss did not improve from 0.55237\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00084: loss did not improve from 0.55237\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.0005497557576745749.\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00085: loss did not improve from 0.55237\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00086: loss improved from 0.55237 to 0.55154, saving model to -086-0.5515-0.7619.hdf5\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00087: loss did not improve from 0.55154\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00088: loss did not improve from 0.55154\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00089: loss did not improve from 0.55154\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0004398046061396599.\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00090: loss did not improve from 0.55154\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.55154\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00092: loss did not improve from 0.55154\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.00035184368025511505.\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00093: loss did not improve from 0.55154\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00094: loss did not improve from 0.55154\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00095: loss did not improve from 0.55154\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0002814749488607049.\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00096: loss did not improve from 0.55154\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00097: loss did not improve from 0.55154\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00098: loss did not improve from 0.55154\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.0002251799684017897.\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00099: loss did not improve from 0.55154\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7619\n",
      "\n",
      "Epoch 00100: loss improved from 0.55154 to 0.55124, saving model to -100-0.5512-0.7619.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27b796bab50>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=InputFeature, y=Label, epochs=100, shuffle=True, batch_size=3, callbacks=CALLBACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x00000279D24EA880>, <tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x00000279D9508760>]\n"
     ]
    }
   ],
   "source": [
    "print(CALLBACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8798076923076923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(roc_auc_score(Label, model.predict(InputFeature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask import render_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/sale/<busy_day>/<high_temperature>')\n",
    "def get_auc(busy_day=None, high_temperature=None):\n",
    "    data = pd.DataFrame({\n",
    "        'busy_day': [int(busy_day)],\n",
    "        'high_temperature':[float(high_temperature)]\n",
    "    })\n",
    "    return \"auc: \" + str(model.predict(data)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses (0.0.0.0)\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.55.187:5000 (Press CTRL+C to quit)\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:47] \"GET /sale/1/30 HTTP/1.1\" 200 -\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:47] \"GET /sale/1/30 HTTP/1.1\" 200 -\n",
      "[2022-07-06 17:28:51,697] ERROR in app: Exception on /sale/1/2- [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"C:\\Users\\gmlkd\\AppData\\Local\\Temp\\ipykernel_14396\\4276189752.py\", line 5, in get_auc\n",
      "    'high_temperature':[float(high_temperature)]\n",
      "ValueError: could not convert string to float: '2-'\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:51] \"GET /sale/1/2- HTTP/1.1\" 500 -\n",
      "[2022-07-06 17:28:51,787] ERROR in app: Exception on /sale/1/2- [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"c:\\Users\\gmlkd\\miniforge3\\envs\\fastcampus\\lib\\site-packages\\flask\\app.py\", line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"C:\\Users\\gmlkd\\AppData\\Local\\Temp\\ipykernel_14396\\4276189752.py\", line 5, in get_auc\n",
      "    'high_temperature':[float(high_temperature)]\n",
      "ValueError: could not convert string to float: '2-'\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:51] \"GET /sale/1/2- HTTP/1.1\" 500 -\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:54] \"GET /sale/1/20 HTTP/1.1\" 200 -\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:55] \"GET /sale/1/20 HTTP/1.1\" 200 -\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:59] \"GET /sale/0/20 HTTP/1.1\" 200 -\n",
      "192.168.55.187 - - [06/Jul/2022 17:28:59] \"GET /sale/0/20 HTTP/1.1\" 200 -\n",
      "192.168.55.187 - - [06/Jul/2022 17:29:05] \"GET /sale/1/38 HTTP/1.1\" 200 -\n",
      "192.168.55.187 - - [06/Jul/2022 17:29:05] \"GET /sale/1/38 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('fastcampus')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d03f6901b6a42dbe3cd1c26aed86af13911a401140e63ddc3b23a4d593814a4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
